{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d800cf5",
   "metadata": {
    "id": "5d800cf5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from lenskit.algorithms.user_knn import UserUser\n",
    "\n",
    "from lenskit import batch, topn, util\n",
    "from lenskit import crossfold as xf\n",
    "from lenskit.algorithms import Recommender, Predictor\n",
    "from lenskit.algorithms.item_knn import ItemItem\n",
    "from lenskit.algorithms.basic import Bias\n",
    "from lenskit.metrics.predict import rmse\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d712341",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4d712341",
    "outputId": "2a0470d8-5030-4945-e64e-1bf7b65ab567"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of news items: 48616\n",
      "Number of unique clicked news: 7307\n",
      "Number of unique users: 49445\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "behaviors = pd.read_csv('./small_training_data/behaviors.tsv', delimiter='\\t', header=None)\n",
    "news = pd.read_csv('./small_training_data/news.tsv', delimiter='\\t', header=None)\n",
    "\n",
    "# Naming columns\n",
    "behaviors.columns = [\"impression_id\", \"user_id\", \"time\", \"history\", \"impressions\"]\n",
    "news.columns = [\"news_id\", \"category\", \"subcategory\", \"title\", \"abstract\", \"url\", \"title_entities\", \"abstract_entities\"]\n",
    "\n",
    "# Remove NaN values in the 'abstract' column\n",
    "news = news.dropna(subset=['abstract'])\n",
    "\n",
    "# Extracting clicked news from behaviors, this is a column of lists of the clicked news (tagget with 1) for each impression\n",
    "behaviors['clicked_news'] = behaviors['impressions'].apply(lambda x: [imp.split('-')[0] for imp in x.split() if imp.split('-')[1] == '1'])\n",
    "\n",
    "# Flattening the clicked news and associating with user_id, that means we divide the lists into one row for each clicked news\n",
    "clicked_news = behaviors.explode('clicked_news')[['user_id', 'clicked_news']].dropna()\n",
    "\n",
    "# Remove clicked news that were removed from the news DataFrame\n",
    "valid_news_ids = set(news['news_id'])\n",
    "# Remove clicked news that were removed from the news DataFrame\n",
    "valid_news_ids = set(news['news_id'])\n",
    "clicked_news = clicked_news[clicked_news['clicked_news'].isin(valid_news_ids)].copy()\n",
    "\n",
    "# Encoding user_id and news_id as categorical variables for memory and computation efficiency\n",
    "clicked_news['user_id'] = clicked_news['user_id'].astype(\"category\")\n",
    "clicked_news['clicked_news'] = clicked_news['clicked_news'].astype(\"category\")\n",
    "\n",
    "print(f\"Total number of news items: {news.shape[0]}\") #48616 unique news\n",
    "print(f\"Number of unique clicked news: {clicked_news['clicked_news'].nunique()}\") #7307 unique news have been clicked\n",
    "print(f\"Number of unique users: {clicked_news['user_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe63a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'user_id' and 'clicked_news' are strings\n",
    "clicked_news['user_id'] = clicked_news['user_id'].astype(str)\n",
    "clicked_news['clicked_news'] = clicked_news['clicked_news'].astype(str)\n",
    "\n",
    "# Rename 'clicked_news' column to 'news_id'\n",
    "clicked_news = clicked_news.rename(columns={'clicked_news': 'news_id'})\n",
    "\n",
    "# Create categorical types without encoding them yet\n",
    "clicked_news['user_id_cat'] = clicked_news['user_id'].astype(\"category\")\n",
    "clicked_news['news_id_cat'] = clicked_news['news_id'].astype(\"category\")\n",
    "\n",
    "# Creating mappings from original IDs to encoded IDs\n",
    "id_to_user = dict(enumerate(clicked_news['user_id_cat'].cat.categories))\n",
    "id_to_news = dict(enumerate(clicked_news['news_id_cat'].cat.categories))\n",
    "\n",
    "# Convert categories to codes (integer encoding)\n",
    "clicked_news['user_id'] = clicked_news['user_id_cat'].cat.codes\n",
    "clicked_news['news_id'] = clicked_news['news_id_cat'].cat.codes\n",
    "\n",
    "# Drop the additional categorical columns if they are not needed\n",
    "clicked_news = clicked_news.drop(columns=['user_id_cat', 'news_id_cat'])\n",
    "\n",
    "# Creating reverse mappings from original IDs to encoded IDs\n",
    "user_to_id = {v: k for k, v in id_to_user.items()}\n",
    "news_to_id = {v: k for k, v in id_to_news.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9a639f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded ID 25103 corresponds to original user ID U53220\n"
     ]
    }
   ],
   "source": [
    "# Testing the mapping\n",
    "sample_id = 25103\n",
    "if sample_id in id_to_user:\n",
    "    print(f\"Encoded ID {sample_id} corresponds to original user ID {id_to_user[sample_id]}\")\n",
    "else:\n",
    "    print(f\"No user found for encoded ID {sample_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f3a2188",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5f3a2188",
    "outputId": "1ad98875-9d95-4740-f3f7-ca979e305469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users: 49445 \n",
      "items: 7307\n"
     ]
    }
   ],
   "source": [
    "# Create a sparse user-item interaction matrix\n",
    "interaction_matrix = coo_matrix((np.ones(clicked_news.shape[0]),\n",
    "                                 (clicked_news['user_id'], clicked_news['news_id'])))\n",
    "\n",
    "print(f\"users: {interaction_matrix.shape[0]} \\nitems: {interaction_matrix.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "-GmRETVNBh-g",
   "metadata": {
    "id": "-GmRETVNBh-g"
   },
   "outputs": [],
   "source": [
    "interaction_matrix_csr = interaction_matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bRWPvWPvDPjZ",
   "metadata": {
    "id": "bRWPvWPvDPjZ"
   },
   "outputs": [],
   "source": [
    "clicked_news_lenskit = clicked_news.rename(columns={'user_id': 'user', 'news_id': 'item'})\n",
    "\n",
    "clicked_news_lenskit['user'] = clicked_news_lenskit['user'].astype(int)\n",
    "clicked_news_lenskit['item'] = clicked_news_lenskit['item'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "iAJX8ErsTOpj",
   "metadata": {
    "id": "iAJX8ErsTOpj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate entries: 1806\n"
     ]
    }
   ],
   "source": [
    "duplicates = clicked_news_lenskit.duplicated(subset=['user', 'item'])\n",
    "print(f\"Number of duplicate entries: {duplicates.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9492b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked_news_lenskit['rating'] = np.ones(len(clicked_news_lenskit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "F75HqpP2CMyA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "F75HqpP2CMyA",
    "outputId": "49249d73-4c9e-45a1-e8f7-9df408d18966",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lenskit.algorithms.user_knn.UserUser at 0x1c271001880>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Train User-User Collaborative Filtering Model\n",
    "user_user = UserUser(15, min_nbrs=3)  # 15 neighbors, minimum 3 neighbors for prediction\n",
    "user_user.fit(clicked_news_lenskit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47d89bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      real_user_id  num_clicks\n",
      "25103       U53220         125\n",
      "35240       U70550         118\n",
      "31128       U63482         109\n",
      "6392        U20833          95\n",
      "13091       U32322          94\n",
      "40439       U79210          87\n",
      "36417       U72489          83\n",
      "40589       U79449          82\n",
      "17935       U40618          82\n",
      "21478       U46937          76\n"
     ]
    }
   ],
   "source": [
    "# Group by 'user_id' and count the number of clicks per user\n",
    "user_click_counts = clicked_news.groupby('user_id').size().reset_index(name='num_clicks')\n",
    "\n",
    "# Sort users by the number of clicks in descending order and get the top 10\n",
    "top_users = user_click_counts.sort_values(by='num_clicks', ascending=False).head(10)\n",
    "\n",
    "# Map internal user IDs to real user IDs\n",
    "top_users['real_user_id'] = top_users['user_id'].map(id_to_user)\n",
    "\n",
    "# Display the top 10 users with real user IDs\n",
    "print(top_users[['real_user_id', 'num_clicks']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3f828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)  # or another number that suits your data\n",
    "\n",
    "# Fit and transform the abstracts to create item profiles\n",
    "item_profiles = vectorizer.fit_transform(news['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "_lSan5o_C4LH",
   "metadata": {
    "id": "_lSan5o_C4LH"
   },
   "outputs": [],
   "source": [
    "def get_clicked_news(real_user_id, clicked_news):\n",
    "    # Convert real user ID to internal user ID\n",
    "    user_id = user_to_id[real_user_id]\n",
    "    return clicked_news[clicked_news['user_id'] == user_id]['news_id'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7bf41da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compute_partial_similarity(clicked_item_profiles, all_item_profiles):\n",
    "    # Compute the similarity between clicked items and all items\n",
    "    similarity_matrix = cosine_similarity(clicked_item_profiles, all_item_profiles)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e93d293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_similar(news_id, similarity_matrix, n=10):\n",
    "    # Get the top-N similar items for a specific item\n",
    "    similar_items = np.argsort(similarity_matrix[news_id, :])[-n-1:-1][::-1]\n",
    "    return similar_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7443192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_for_user(real_user_id, clicked_news, item_profiles, user_to_id, id_to_news, n=10):\n",
    "    # Get clicked news by the user\n",
    "    clicked_items = get_clicked_news(real_user_id, clicked_news, user_to_id)\n",
    "    \n",
    "    # Extract item profiles for clicked items\n",
    "    clicked_item_profiles = item_profiles[clicked_items, :]\n",
    "    \n",
    "    # Compute similarity matrix\n",
    "    similarity_matrix = compute_partial_similarity(clicked_item_profiles, item_profiles)\n",
    "    \n",
    "    # Get top-N similar items for each clicked item\n",
    "    recommended_items = set()\n",
    "    for idx, item_id in enumerate(clicked_items):\n",
    "        similar_items = get_top_n_similar(idx, similarity_matrix, n)\n",
    "        recommended_items.update(similar_items)\n",
    "    \n",
    "    # Remove items that the user has already clicked on\n",
    "    recommended_items = recommended_items - set(clicked_items)\n",
    "    \n",
    "    # Convert internal item IDs to real item IDs\n",
    "    recommended_real_items = [id_to_news[item_id] for item_id in recommended_items]\n",
    "    \n",
    "    return recommended_real_items[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a6ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_items = recommend_for_user(user_id, clicked_news, item_profiles, n_recommendations)\n",
    "\n",
    "print(f\"Recommended items for user {user_id}: {recommended_items}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
