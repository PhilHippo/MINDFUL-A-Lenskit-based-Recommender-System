{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b2350fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37307b34",
   "metadata": {},
   "source": [
    " # Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c971fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "behaviors = pd.read_csv('./small_training_data/behaviors.tsv', delimiter='\\t', header=None)\n",
    "news = pd.read_csv('./small_training_data/news.tsv', delimiter='\\t', header=None)\n",
    "\n",
    "# Naming columns\n",
    "behaviors.columns = [\"impression_id\", \"user_id\", \"time\", \"history\", \"impressions\"]\n",
    "news.columns = [\"news_id\", \"category\", \"subcategory\", \"title\", \"abstract\", \"url\", \"title_entities\", \"abstract_entities\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5931b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaN values in the 'abstract' column\n",
    "news = news.dropna(subset=['abstract'])\n",
    "\n",
    "# list of valid news (with some abstract)\n",
    "valid_news_ids = set(news['news_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03927cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting clicked news from behaviors, this is a column of lists of the clicked news (tagget with 1) for each impression\n",
    "behaviors['clicked_news'] = behaviors['impressions'].apply(lambda x: [imp.split('-')[0] for imp in x.split() if imp.split('-')[1] == '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cb35b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing unused columns\n",
    "behaviors = behaviors[[\"impression_id\", \"user_id\", \"clicked_news\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6382eae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening the clicked news and associating with user_id, that means we divide the lists into one row for each clicked news\n",
    "clicked_news = behaviors.explode('clicked_news')[['user_id', 'clicked_news']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c005d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove non valid news from interactions\n",
    "clicked_news = clicked_news[clicked_news['clicked_news'].isin(valid_news_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4212f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering users with more than 4 news clicked since the distribution is 'ultra-skewed'\n",
    "clicked_news = clicked_news.groupby('user_id').filter(lambda x: len(x) > 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba6e56aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'clicked_news' column to 'news_id'\n",
    "clicked_news = clicked_news.rename(columns={'clicked_news': 'news_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9b9765c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique clicked news: 6522\n",
      "Number of unique users:        15418 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique clicked news: {clicked_news['news_id'].nunique()}\")\n",
    "print(f\"Number of unique users:        {clicked_news['user_id'].nunique()} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e983ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = news.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9261f15b",
   "metadata": {},
   "source": [
    "## in the cell below we create mappings from real id's to indexes, and create clicked_news_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a66c0c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create categorical types without encoding them yet\n",
    "clicked_news['user_id_cat'] = clicked_news['user_id'].astype(\"category\")\n",
    "clicked_news['news_id_cat'] = clicked_news['news_id'].astype(\"category\")\n",
    "\n",
    "# Creating mappings from original IDs to encoded IDs\n",
    "id_to_user = dict(enumerate(clicked_news['user_id_cat'].cat.categories))\n",
    "id_to_news = dict(enumerate(clicked_news['news_id_cat'].cat.categories))\n",
    "\n",
    "# Convert categories to codes (integer encoding)\n",
    "clicked_news_encoded = pd.DataFrame(columns=['user', 'item'])\n",
    "clicked_news_encoded['user'] = clicked_news['user_id_cat'].cat.codes\n",
    "clicked_news_encoded['item'] = clicked_news['news_id_cat'].cat.codes\n",
    "\n",
    "# Drop the additional categorical columns if they are not needed\n",
    "clicked_news = clicked_news.drop(columns=['user_id_cat', 'news_id_cat'])\n",
    "\n",
    "# Creating reverse mappings from original IDs to encoded IDs\n",
    "user_to_id = {v: k for k, v in id_to_user.items()}\n",
    "news_to_id = {v: k for k, v in id_to_news.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d4d0e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users: 15418 \n",
      "items: 6522\n"
     ]
    }
   ],
   "source": [
    "# Create a sparse user-item interaction matrix\n",
    "interaction_matrix = coo_matrix((np.ones(clicked_news_encoded.shape[0]),\n",
    "                                 (clicked_news_encoded['user'], clicked_news_encoded['item'])))\n",
    "\n",
    "print(f\"users: {interaction_matrix.shape[0]} \\nitems: {interaction_matrix.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbeb967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform into compressed sparse row\n",
    "interaction_matrix_csr = interaction_matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "173c8f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked_news_encoded['rating'] = np.ones(len(clicked_news_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5396cae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         user  item  rating\n",
      "1       14889   756     1.0\n",
      "5        1803  1190     1.0\n",
      "5        1803  2565     1.0\n",
      "9        7888  4810     1.0\n",
      "10      14512  5700     1.0\n",
      "...       ...   ...     ...\n",
      "156963   6291  1261     1.0\n",
      "156963   6291  4396     1.0\n",
      "156963   6291  2904     1.0\n",
      "156963   6291   915     1.0\n",
      "156963   6291  1137     1.0\n",
      "\n",
      "[155443 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(clicked_news_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2c158a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id  num_of_clicks\n",
      "0      U53220            125\n",
      "1      U70550            118\n",
      "2      U63482            109\n",
      "3      U20833             95\n",
      "4      U32322             94\n",
      "...       ...            ...\n",
      "13230  U91963              5\n",
      "13231  U65567              5\n",
      "13232    U417              5\n",
      "13233  U63788              5\n",
      "15417   U5480              5\n",
      "\n",
      "[15418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "user_click_counts = clicked_news['user_id'].value_counts().reset_index()\n",
    "user_click_counts.columns = ['user_id', 'num_of_clicks']\n",
    "user_click_counts_sorted = user_click_counts.sort_values(by='num_of_clicks', ascending=False)\n",
    "print(user_click_counts_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2118b690",
   "metadata": {},
   "source": [
    "# Content based recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbaeefbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing the 'abstract' column of news\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "news_profiles = vectorizer.fit_transform(news['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79e09e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "royals\n"
     ]
    }
   ],
   "source": [
    "# Reversing the vocabulary dictionary\n",
    "reverse_vocab = {v: k for k, v in vectorizer.vocabulary_.items()}\n",
    "\n",
    "print(reverse_vocab.get(3845))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cb48ec",
   "metadata": {},
   "source": [
    "This is a matrix that holds the similarity scores between all pairs of news items. It's a  square matrix where each row and column corresponds to a news item, and the entry [i, j] gives the similarity between news item i and news item j. the diagonal is full of ones for obvious reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c3112e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the cosine similarity matrix\n",
    "news_similarity = cosine_similarity(news_profiles, dense_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b64f0172",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_id_to_news = news['news_id'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1e6e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_news(user_id, interaction_matrix, news_similarity, top_n=5):\n",
    "    \"\"\"\n",
    "    Recommend top N news items for a given user.\n",
    "    \n",
    "    Parameters:\n",
    "        user_id (str): The user for whom to make recommendations.\n",
    "        interaction_matrix (csr_matrix): User-item interaction matrix.\n",
    "        news_similarity (csr_matrix): Item-item similarity matrix.\n",
    "        top_n (int): Number of items to recommend.\n",
    "        \n",
    "    Returns:\n",
    "        list: List of recommended item indices.\n",
    "    \"\"\"\n",
    "    user_id = user_to_id[user_id]\n",
    "    \n",
    "    # Get the user's past interactions (list of news ids that the user has interacted with)\n",
    "    user_interactions = interaction_matrix[user_id, :].nonzero()[1]\n",
    "    \n",
    "    # Sum the similarities of the interacted items \n",
    "    similarity_sum = np.sum(news_similarity[user_interactions, :], axis=0) #shape = (n_interactions, all_news)\n",
    "    \n",
    "    # Remove already interacted items\n",
    "    similarity_sum[0, user_interactions] = 0\n",
    "    \n",
    "    # Get top N item indices\n",
    "    recommended_news_ids = np.argsort(similarity_sum)[0, -top_n:][::-1]\n",
    "    \n",
    "    # Convert indices to original news IDs\n",
    "    recommended_news = [all_id_to_news[idx] for idx in recommended_news_ids.tolist()[0]]\n",
    "    \n",
    "    return recommended_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c09405c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended news for user U53220:\n",
      "['N4830', 'N17496', 'N11545', 'N64885', 'N35290', 'N6405', 'N2445', 'N15320', 'N45022', 'N12262']\n"
     ]
    }
   ],
   "source": [
    "# Recommend for a user\n",
    "user_id = 'U53220'\n",
    "recommended_news_indices = recommend_news(user_id, interaction_matrix_csr, news_similarity, top_n=10)\n",
    "\n",
    "print(f\"Recommended news for user {user_id}:\")\n",
    "print(recommended_news_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf88419",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ad33950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "test_behaviors = pd.read_csv('./small_test_data/behaviors.tsv', delimiter='\\t', header=None)\n",
    "test_news = pd.read_csv('./small_test_data/news.tsv', delimiter='\\t', header=None)\n",
    "\n",
    "# Naming columns\n",
    "test_behaviors.columns = [\"impression_id\", \"user_id\", \"time\", \"history\", \"impressions\"]\n",
    "test_news.columns = [\"news_id\", \"category\", \"subcategory\", \"title\", \"abstract\", \"url\", \"title_entities\", \"abstract_entities\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8899f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaN values in the 'abstract' column\n",
    "test_news = test_news.dropna(subset=['abstract'])\n",
    "\n",
    "# list of valid news (with some abstract)\n",
    "test_valid_news_ids = set(test_news['news_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a85f05d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting clicked news from behaviors, this is a column of lists of the clicked news (tagget with 1) for each impression\n",
    "test_behaviors['clicked_news'] = test_behaviors['impressions'].apply(lambda x: [imp.split('-')[0] for imp in x.split() if imp.split('-')[1] == '1'])\n",
    "\n",
    "#removing unused columns\n",
    "test_behaviors = test_behaviors[[\"impression_id\", \"user_id\", \"clicked_news\"]]\n",
    "\n",
    "# Flattening the clicked news and associating with user_id, that means we divide the lists into one row for each clicked news\n",
    "test_clicked_news = test_behaviors.explode('clicked_news')[['user_id', 'clicked_news']]\n",
    "\n",
    "#remove non valid news from interactions\n",
    "test_clicked_news = test_clicked_news[test_clicked_news['clicked_news'].isin(test_valid_news_ids)]\n",
    "\n",
    "# Rename 'clicked_news' column to 'news_id'\n",
    "test_data = test_clicked_news.rename(columns={'clicked_news': 'news_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "701cb1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique clicked news: 2115\n",
      "Number of unique users:        48139 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique clicked news: {test_data['news_id'].nunique()}\")\n",
    "print(f\"Number of unique users:        {test_data['user_id'].nunique()} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab015439",
   "metadata": {},
   "source": [
    "### Since it's a content-based recommender system we ran into the cold start problem from users present in the test data but not in the training data, so we just recommend them items from the most popular news "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21adffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_popularity = clicked_news['news_id'].value_counts()\n",
    "\n",
    "# Calculate the click threshold for the top percentile\n",
    "threshold = np.percentile(news_popularity, 98)\n",
    "\n",
    "# Get the most popular news items\n",
    "popular_news = news_popularity[news_popularity >= threshold].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb21a19a",
   "metadata": {},
   "source": [
    "## Precision@k and Recall@k and nCDG@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39ddf2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = {} #{'user_id': [list of recommended news_ids]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f33f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of user_ids from test_data and training data\n",
    "test_data_user_ids = set(test_data['user_id'].unique())\n",
    "\n",
    "train_data_user_ids = set(clicked_news['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48dfd296",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for user_id in test_data_user_ids:\n",
    "    if user_id not in train_data_user_ids:\n",
    "        # New user or user not in test data\n",
    "        recommendations[user_id] = random.sample(popular_news, 5)  # Recommend random news from popular news items\n",
    "    else:\n",
    "        recommended_news_indices = recommend_news(user_id, interaction_matrix_csr, news_similarity, top_n=10)\n",
    "        recommendations[user_id] = [idx for idx in recommended_news_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec05261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(recommended_list, relevant_list, k):\n",
    "    \"\"\"\n",
    "    Compute Precision at K.\n",
    "    \n",
    "    Parameters:\n",
    "        recommended_list (list): List of recommended items.\n",
    "        relevant_list (list): List of relevant items.\n",
    "        k (int): Number of recommendations to consider.\n",
    "        \n",
    "    Returns:\n",
    "        float: Precision at K score.\n",
    "    \"\"\"\n",
    "    return len(set(recommended_list[:k]) & set(relevant_list)) / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f320af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(recommended_list, relevant_set, k):\n",
    "    \"\"\"Return the recall at k.\"\"\"\n",
    "    return len(set(recommended_list[:k]) & set(relevant_set)) / len(relevant_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03ad74f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(recommended_list, relevant_set, k):\n",
    "    \"\"\"Return the NDCG at k.\"\"\"\n",
    "    dcg = 0\n",
    "    idcg = sum([1 / math.log(i + 2, 2) for i in range(min(k, len(relevant_set)))])\n",
    "    for i, item in enumerate(recommended_list[:k]):\n",
    "        if item in relevant_set:\n",
    "            dcg += 1 / math.log(i + 2, 2)\n",
    "    return dcg / idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1dae9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Precision@5: 0.0017\n",
      "Mean Recall@5: 0.0007\n",
      "Mean NDCG@5: 0.0015\n"
     ]
    }
   ],
   "source": [
    "k = 5 # or any value you choose\n",
    "\n",
    "precision_values = []\n",
    "recall_values = []\n",
    "ndcg_values = []\n",
    "\n",
    "for user_id, recommended_items in recommendations.items():\n",
    "    relevant_items = test_data[test_data['user_id'] == user_id]['news_id'].tolist()\n",
    "    \n",
    "    if relevant_items:  # if the user has any relevant items\n",
    "        \n",
    "        precision = precision_at_k(recommended_items, relevant_items, k)\n",
    "        recall = recall_at_k(recommended_items, relevant_items, k)\n",
    "        ndcg = ndcg_at_k(recommended_items, relevant_items, k)\n",
    "        \n",
    "        precision_values.append(precision)\n",
    "        recall_values.append(recall)\n",
    "        ndcg_values.append(ndcg)\n",
    "\n",
    "# Averaging across all users to get the final metric value\n",
    "mean_precision = np.mean(precision_values)\n",
    "mean_recall = np.mean(recall_values)\n",
    "mean_ndcg = np.mean(ndcg_values)\n",
    "\n",
    "print(f\"Mean Precision@{k}: {mean_precision:.4f}\")\n",
    "print(f\"Mean Recall@{k}: {mean_recall:.4f}\")\n",
    "print(f\"Mean NDCG@{k}: {mean_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d79a91",
   "metadata": {},
   "source": [
    "I think it's due to the sparsity and cold start problem, we have many users without interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "082109a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_test_data = test_data.groupby('user_id').filter(lambda x: len(x) > 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2b1fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = {} #{'user_id': [list of recommended news_ids]}\n",
    "\n",
    "# Set of user_ids from test_data and training data\n",
    "test_data_user_ids = set(filtered_test_data['user_id'].unique())\n",
    "\n",
    "train_data_user_ids = set(clicked_news['user_id'].unique())\n",
    "\n",
    "for user_id in test_data_user_ids:\n",
    "    if user_id not in train_data_user_ids:\n",
    "        # New user or user not in test data\n",
    "        recommendations[user_id] = random.sample(popular_news, 5)  # Recommend random news from popular news items\n",
    "    else:\n",
    "        recommended_news_indices = recommend_news(user_id, interaction_matrix_csr, news_similarity, top_n=10)\n",
    "        recommendations[user_id] = [idx for idx in recommended_news_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fda5dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Precision@5: 0.0021\n",
      "Mean Recall@5: 0.0009\n",
      "Mean NDCG@5: 0.0017\n"
     ]
    }
   ],
   "source": [
    "k = 5  # or any value you choose\n",
    "\n",
    "precision_values = []\n",
    "recall_values = []\n",
    "ndcg_values = []\n",
    "\n",
    "for user_id, recommended_items in recommendations.items():\n",
    "    relevant_items = test_data[test_data['user_id'] == user_id]['news_id'].tolist()\n",
    "    \n",
    "    if relevant_items:  # if the user has any relevant items\n",
    "        \n",
    "        precision = precision_at_k(recommended_items, relevant_items, k)\n",
    "        recall = recall_at_k(recommended_items, relevant_items, k)\n",
    "        ndcg = ndcg_at_k(recommended_items, relevant_items, k)\n",
    "        \n",
    "        precision_values.append(precision)\n",
    "        recall_values.append(recall)\n",
    "        ndcg_values.append(ndcg)\n",
    "\n",
    "# Averaging across all users to get the final metric value\n",
    "mean_precision = np.mean(precision_values)\n",
    "mean_recall = np.mean(recall_values)\n",
    "mean_ndcg = np.mean(ndcg_values)\n",
    "\n",
    "print(f\"Mean Precision@{k}: {mean_precision:.4f}\")\n",
    "print(f\"Mean Recall@{k}: {mean_recall:.4f}\")\n",
    "print(f\"Mean NDCG@{k}: {mean_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6299b60d",
   "metadata": {},
   "source": [
    "### In fact we can see that is precision increases if we consider users with more than n = 10 interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d517852",
   "metadata": {},
   "source": [
    "# Group recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1fe8d11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON string from a file\n",
    "with open(\"grouped_dict.json\", \"r\") as f:\n",
    "    grouped_dict_json = f.read()\n",
    "\n",
    "# Convert the JSON string back to a dictionary\n",
    "groups_dict = json.loads(grouped_dict_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "219cba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenskit import batch, topn, util\n",
    "from lenskit import crossfold as xf\n",
    "from lenskit.algorithms import als, Recommender\n",
    "\n",
    "#  Set up and train the algorithm\n",
    "algo = als.BiasedMF(100)  # we can change number of factor\n",
    "train, test = next(xf.partition_users(clicked_news_encoded, 1, xf.SampleFrac(0.2)))\n",
    "model = algo.fit(train)  # Use fit to train the model\n",
    "\n",
    "all_recommendations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3ce53d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_recs(group_users, model = model, train = train):\n",
    "  train_items = train['item'].unique()\n",
    "  for user in group_users:\n",
    "      user_scores = []\n",
    "      for item in train_items:\n",
    "          score = model.predict_for_user(user, [item])\n",
    "          user_scores.append((item, score.iloc[0] if not score.empty else 0))\n",
    "\n",
    "      user_recs = pd.DataFrame(user_scores, columns=['item', 'score'])\n",
    "      top_recs = user_recs.sort_values(by='score', ascending=False).head(10)\n",
    "      all_recommendations.append(top_recs)\n",
    "\n",
    "  reclist = pd.concat(all_recommendations)\n",
    "\n",
    "  least_misery_scores = reclist.groupby('item').score.min().reset_index()  # Using min for \"least misery\"\n",
    "  group_top_recs = least_misery_scores.sort_values(by='score', ascending=False).head(10) # top 10\n",
    "\n",
    "  return group_top_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cf3bcc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   item  score\n",
      "0  1013    NaN\n",
      "1  1120    NaN\n",
      "2  1190    NaN\n",
      "3  1476    NaN\n",
      "4  2565    NaN\n",
      "5  2808    NaN\n",
      "6  5060    NaN\n",
      "7  5482    NaN\n",
      "8  5700    NaN\n",
      "9  5926    NaN\n"
     ]
    }
   ],
   "source": [
    "group_top_recs = group_recs(groups_dict['Group 3'])\n",
    "print(group_top_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00776fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
